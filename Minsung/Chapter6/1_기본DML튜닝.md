# 6.1 기본 DML 튜닝

DML에 성능을 미치는 요소에 어떤 것들이 있는지부터 살펴봅시다.



## 6.1.1 DML 성능에 영향을 미치는 요소

* 인덱스
* 무결성 제약
* 조건절
* 서브쿼리
* Redo 로깅
* Undo 로깅
* Lock
* 커밋

<br>

### 인덱스와 DML 성능

테이블에 레코드를 입력하면 인덱스에도 입력해야합니다.

인덱스는 정렬된 자료구조이므로 수직적 탐색을 통해 입력할 블록을 찾아야합니다.

따라서 DML 성능에 미치는 영향이 큽니다.

이는 삭제와 수정도 마찬가지입니다.

<br>

### 무결성 제약과 DML 성능

데이터베이스에 논리적으로 의미 있는 자료만 저장되게 하는 데이터 무결성 규칙으로는 아래 네 가지가 있습니다.

* 개체 무결성
* 참조 무결성
* 도메인 무결성
* 사용자 정의 무결성

이들 규칙을 애플리케이션으로 구현할 수도 있지만, DBMS에서 PK, FK, Check, Not Null 같은 제약을 설정하면 더 완벽하게 데이터 무결성을 지켜낼 수 있습니다.

PK와 FK는 실제 데이터를 조회해봐야하기 때문에 성능에 영향을 더 미칩니다.

<br>

### Redo 로깅과 DML 성능

오라클은 데이터파일과 컨트롤 파일에 가해지는 모든 변경사항을 Redo 로그에 기록합니다.

Redo 로그는 트랜잭션 데이터가 어떤 이유에서건 유실됐을 때, 트랜잭션을 재현함으로써 유실 이전 상태로 복구하는 데 사용합니다.

DML을 수행할 때마다 Redo 로그를 생성해야 하므로 Redo 로깅은 성능에 영향을 미칩니다.

따라서 INSERT 작업에 대해 Redo 로깅을 생략 가능하기도 합니다.

<br>

### Undo 로깅과 DML 성능

과거에는 Rollback이라는 용어를 주로 사용했지만 9i부터 오라클은 Undo라는 용어를 사용하고 있습니다.

Redo가 트랜잭션을 재현함으로써 과거를 현재 상태로 되돌리는데 사용했다면 Undo는 트랜잭션을 Rollback함으로써 현재를 과거 상태로 되돌리는데 사용합니다.

DML을 수행할 때마다 Undo를 생성해야 하므로 Undo 로깅은 DML 성능에 영향을 미칩니다.

하지만 오라클은 Undo를 생략하는 기능은 제공하고 있지 않습니다.

<br>

### Lock과 DML 성능

Lock은 DML 성능에 매우 크고 직접적인 영향을 미칩니다.

Lock을 필요 이상으로 자주, 길게 사용하거나 레벨을 높일수록 DML 성능은 느려집니다.

그렇다고 Lock을 너무 적게, 짧게 사용하거나 필요한 레벨 이하로 낮추면 데이터 품질이 나빠집니다.

성능과 데이터 품질은 trade-off입니다.

<br>

### 커밋과 DML 성능

커밋은 DML과 별개로 실행하지만 DML을 끝내려면 커밋까지 완료해야 하므로 서로 밀접한 관련이 있습니다.

DML이 Lock에 의해 Blocking된 경우, 커밋은 DML 성능과 직결됩니다.

DML을 완료할 수 있게 Lock을 푸는 열쇠가 바로 커밋입니다.

모든 DBMS가 Fast Commit을 구현하고 있습니다.

이는 갱신한 데이터가 아무리 많아도 커밋만큼은 빠르게 처리할 수 있게 해줍니다.

커밋의 내부 메커니즘을 통해 그 이유를 살펴봅시다.

#### (1) DB 버퍼캐시

DB에 접속한 사용자를 대신해 모든 일을 처리하는 서버 프로세스는 버퍼캐시를 통해 데이터를 읽고 씁니다.

버퍼캐시에서 변경된 블록(Dirty 블록)을 모아 주기적으로 데이터파일에 일괄 기록하는 작업은 DBWR(Database Writer)프로세스가 맡습니다.

#### (2) Redo 로그버퍼

버퍼캐시는 휘발성이므로 DBWR 프로세스가 Dirty 블록들을 데이터파일에 반영할 때까지 불안한 상태라고 생각할 수 있습니다.

하지만 버퍼캐시에 가한 변경사항을 Redo 로그에도 기록해 두었으므로 안심해도 됩니다.

버퍼캐시 데이터가 유실되더라도 Redo 로그를 이용해 언제든 복구할 수 있기 때문입니다.

그런데 Redo 로그도 파일입니다. 

Append 방식으로 기록하더라도 디스크 I/O는 느립니다.

Redo 로깅 성능 문제를 해결하기 위해 오라클은 로그버퍼를 이용합니다.

Redo 로그 파일에 기록하기 전에 먼저 로그버퍼에 기록하는 방식입니다.

로그버퍼에 기록한 내용은 나중에 LGWR(Log Writer) 프로세스가 Redo 로그파일에 일괄 기록합니다.

#### (3) 트랜잭션 데이터 저장 과정

한 트랜잭션이 데이터를 변경하고 커밋하는 과정, 그리고 변경된 블록을 데이터파일에 기록하는 과정은 다음과 같습니다.

1. DML 문을 실행하면 Redo 로그버퍼에 변경사항을 기록합니다.
2. 버퍼블록에서 데이터를 변경합니다. 물론 버퍼캐시에서 블록을 찾지 못하면 데이터파일에서 읽는 작업부터 합니다.
3. 커밋합니다.
4. LGWR 프로세스가 Redo 로그버퍼 내용을 로그파일에 일괄 저장합니다.
5. DBWR 프로세스가 변경된 버퍼블록들은 데이터파일에 일괄 저장합니다.

오라클은 데이터를 변경하기 전에 항상 로그부터 기록합니다.

서버 프로세스가 버퍼블록에서 데이터를 변경하기 전에 Redo 로그버퍼를 먼저 기록하는 이유입니다.

또한 DBWR 프로세스가 Dirty 블록을 디스크에 기록하기 전에 LGWR 프로세스가 Redo 로그파일에 로그를 먼저 기록하는 이유이기도 합니다.

이를 Write Ahead Logging이라고 부릅니다.



메모리 버퍼 캐시가 휘발성이어서 Redo 로그를 남기는데, Redo 로그마저도 휘발성 로그버퍼에 기록한다면 트랜잭션 데이터를 안전하게 지킬 수 있느냐는 문제입니다.

커밋한 트랜잭션의 영속성을 어떻게 보장할 것인가, 오라클은 이 문제를 어떻게 해결할까요

잠자던 DBWR와 LGWR 프로세스는 주기적으로 깨어나 각각 Dirty 블록과 Redo 로그버퍼를 파일에 기록합니다.

LGWR 프로세스는 서버 프로세스가 커밋을 발행했다고 신호를 보낼 때도 깨어나서 활동을 시작합니다.

적어도 커밋시점에는 Redo 로그버퍼 내용을 로그파일에 기록한다는 뜻입니다.

이를 Log Force at Commit이라고 부릅니다.

서버 프로세스가 변경한 버퍼블록들을 디스크에 기록하지 않았더라도 커밋 시점에 Redo 로그를 디스크에 안전하게 기록했다면 그 순간부터 트랜잭션의 영속성은 보장됩니다.

#### (4) 커밋 = 저장버튼

커밋은 문서 작업 도중 저장버튼을 누르는 것과 같습니다.

저장을 완료할 때까지 서버 프로세스는 다음 작업을 진행할 수 없습니다.

Redo 로그버퍼에 기록된 내용을 디스크에 기록하도록 LGWR 프로세스에 신호를 보낸 후 작업을 완료했다는 신호를 받아야 다음 작업을 진행할 수 있습니다.

LGWR 프로세스가 Redo 로그를 기록하는 작업은 디스크 I/O 작업입니다.

그래서 커밋은 생각보다 느립니다.

<br>

트랜잭션을 필요 이상으로 길게 정의함으로써 오랫동안 커밋하지 않는 것도 문제지만 너무 자주 커밋하는 것도 문제입니다.

오랫동안 커밋하지 않은 채 데이터를 계속 갱신하면 Undo 공간이 부족해져 시스템 장애 상황을 유발할 수 있습니다.

트랜잭션을 논리적으로 잘 정의함으로써 불필요한 커밋이 발생하지 않도록 구현해야 합니다.

<br>

## 6.1.2 데이터베이스 Call과 성능

SQL 트레이스 Call 통계가 보여주듯, SQL은 아래 세 단계로 나누어 실행됩니다.

* Parse Call : SQL 파싱과 최적화를 수행하는 단계입니다. SQL과 실행계획을 라이브러리 캐시에서 찾으면, 최적화 단계는 생략할 수 있습니다.
* Execute Call : 말 그대로 SQL을 실행하는 단계입니다. DML은 이 단계에서 모든 과정이 끝나지만 SELECT문은 Fetch 단계를 거칩니다.
* Fetch Call : 데이터를 읽어서 사용자에게 결과집합을 전송하는 과정으로 SELECT문에서만 나타납니다. 전송할 데이터가 많을 때는 Fetch Call이 여러 번 발생합니다.

Call이 어디서 발생하느냐에 따라 User Call과 Recursive Call로 나눌 수 있습니다.

* User Call은 네트워크를 경유해 DBMS 외부로부터 인입되는 Call입니다. WAS 서버에서 발생하는 Call을 말합니다.
* Recursive Call은 DBMS 내부에서 발생하는 Call입니다. 



User Call이든 Recursive Call이든, SQL을 실행할 때마다 Parse, Execute, Fetch Call 단계를 거칩니다.

데이터베이스에 Call이 많으면 성능은 느릴 수 밖에 없습니다.

특히 네트워크를 경유하는 User Call이 성능에 미치는 영향은 매우 큽니다.

<br>

### 절차적 루프 처리

쿼리를 통해 테이블에 insert할 때(Recursive Call)와 JAVA와 같은 프로그램으로 수행하면서 네트워크를 경유하여 insert를 할 때(User Call)은 성능차이가 많이 납니다.

<br>

### One SQL의 중요성

업무 로직이 복잡하면 절차적으로 처리할 수 밖에 없지만 그렇지 않다면 가급적 One SQL로 구현하려고 노력해야 합니다.

절차적으로 구현된 프로그램을 One SQL로 구현하기 위해 아래와 같은 방법이 유용합니다.

* Insert Into Select
* 수정가능 조인 뷰
* Merge 문

<br>

## 6.1.3 Array Processing 활용

Array Processing 기능을 활용하면 One SQL로 구현하지 않고도 Call 부하를 획기적으로 줄일 수 있습니다.

<br>

## 6.1.4 인덱스 및 제약 해제를 통한 대량 DML 튜닝

인덱스와 무결성 제약 조건은 DML 성능에 큰 영향을 끼칩니다.

그렇다고 이들 기능을 해제할 순 없습니다.

하지만 동시 트랜잭션 없이 대량 데이터를 적재하는 배치 프로그램에서는 이들 기능을 해제함으로써 큰 성능개선 효과를 얻을 수 있습니다.

<br>

### PK 제약에 Unique 인덱스를 사용한 경우

데이터 입력시간과 제약 활성화 및 인덱스 재생성 시간을 합쳐도 기존보다 훨씬 더 빨리 작업을 마칠 수 있습니다.

데이터 무결성에 확신이 없다면 데이터를 입력하기 전 확인해야 합니다.

<br>

### PK 제약에 Non-Unique 인덱스를 사용한 경우

이 역시 빨리 작업을 마칠 수 있습니다.

<br>

## 6.1.5 수정가능 조인 뷰

### 전통적인 방식의 UPDATE

``` SQL
update 고객 c
set 최종 거래 일시 = (select max(거래일시) from 거래 
                -- ....
               ),
    최근 거래횟수 = (select count(*) 
              -- ...
              ),
    최근거래금액 = (select sum(거래금액)
              -- ....
    )
where exists (select 'x' from 거래 
             -- ...
             )
```

위 UPDATE문을 아래와 같이 개선할 수 있습니다.

```SQL
update 고객 c
set (최종거래일시, 최근거래횟수, 최근거래금액) = (select max(거래일시), count(*), sum(거래금액)
                               -- ...
                               )
where exists (select 'x' from 거래 
             -- ...
             )
```



총 고객 수가 아주 많다면 Exists 서브쿼리를 아래와 같이 해시 세미 조인으로 유도하는 것을 고려할 수 있습니다.

```SQL
update 고객 c
set (최종거래일시, 최근거래횟수, 최근거래금액) = (select max(거래일시), count(*), sum(거래금액)
                               -- ...
                               )
where exists (select /* unnest hash_sj */ 'x' from 거래 
             -- ...
             )
```



다른 테이블과 조인이 필요할 때 전통적인 UPDATE문을 사용하면 비효율을 완전히 해소할 수 없습니다.

<br>

### 수정가능 조인 뷰

수정가능 조인 뷰를 활용하면 참조 테이블과 두 번 조인하는 비효율을 없앨 수 있습니다.

조인 뷰는 FROM 절에 두 개 이상 테이블을 가진 뷰를 가르키며,
수정 가능 조인 뷰는 말 그대로 입력, 수정, 삭제가 허용되는 조인 뷰를 말합니다.

>  원하는 결과가 아니다?

1쪽 집합에 PK 제약을 설정하거나 Unique 인덱스를 생성해야 수정가능 조인뷰를 통한 입력/수장/삭제가 가능합니다.

위와 같이 PK 제약을 설정하면 EMP 테이블은 키-보존 테이블이 되고,

DEPT 테이블은 비 키-보존 테이블로 남습니다.

<br>

### 키 보존 테이블이란?

키 보존 테이블이란 조인된 결과집합을 통해서도 중복 값 없이 Unique하게 식별이 가능한 테이블을 말합니다.





## 6.1.6 MERGE 문 활용

DW에서 가장 흔히 발생하는 오퍼레이션은 기간계 시스템에서 가져온 신규 트랜잭션 데이터를 반영함으로써 두 시스템 간 데이터를 동기화하는 작업입니다.

1. 전일 발생한 변경 데이터를 기간계 시스템으로부터 추출(Extraction)

   ```
   create table customer_delta
   as
   select * from customer
   where mod_dt >= trunc(sysdate) - 1
   and mod_dt < tunc(sysdate)
   ```

   

2. CUSTOMER_DELTA 테이블을 DW 시스템으로 전송

3. DW 시스템으로 적재

   ```
   merge into customer t using customer_delta s on (t.cust_id = s.cust_id)
   when matched then update
   	set t.cust_nm = s.cust_nm, t.email = s.email, ...
   when not matched then insert
   	(cust_id ...) values
     (s.cust_id ...);
   ```

   

MERGE 문은 Source(Customer_Delta) 테이블 기준으로 Target 테이블과 Left Outer 방식으로 조인해서 조인에 성공하면 UPDATE, 실패하면 INSERT 합니다.

그래서 UPSERT라고 부릅니다.



### Merge Into 활용 예

저장하려는 레코드가 기본에 있던 것이면 UPDATE를 수행하고, 그렇지 않으면 INSERT 하려고 합니다.

아래와 같이 처리하면 SQL을 항상 두 번씩 수행합니다.

```
select count(*) into :cnt from dept where deptno = :val1;

if :cnt = 0 then
	insert into dept(deptno, dname, loc) values(:val1, :val2, :val3);
else
	update dept set dname = :val2, loc = val3 where deptno =: val1;
end if;
```



아래와 같이 하면 SQL을 최대 두 번 수행합니다.

```
update dept set dname = :val2, loc = :val3 where deptno = :val1;

if sql%rowcount = 0 then
	insert into dept(deptno, dname, loc) values(:val1, val2, val3);
end if;
```

